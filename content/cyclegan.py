# -*- coding: utf-8 -*-
"""CycleGAN_vangogh.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zao76Ao2dEsTjgoV6Zk5qWfXV8LA9tMB
"""

from __future__ import absolute_import, division, print_function, unicode_literals

import PIL
from tensorflow_examples.models.pix2pix import pix2pix
import tensorflow as tf

from IPython.display import clear_output
import matplotlib.pyplot as plt
import matplotlib as mpl

from imageio import imread
import numpy as np
import cv2

import time
import os

from content.dataloader import DataLoader


class CycleGAN():

    def __init__(self):
        # 사용할 Hyperparameter를 지정한다.
        self.IMG_WIDTH = 256
        self.IMG_HEIGHT = 256
        self.BATCH_SIZE = 1
        self.BUFFER_SIZE = 1000

        # Input shape
        self.img_rows = 256
        self.img_cols = 256
        self.channels = 3
        self.model_dir = "./models"
        self.num_of_trials = 27
        self.img_shape = (self.img_rows, self.img_cols, self.channels)

        '''
        # Configure data loader
        self.dataset_name = 'color_gray'
        # DataLoaderオブジェクトを使用して前処理されたデータセットをインポートする
        self.data_loader = DataLoader(dataset_name=self.dataset_name,
                                      img_res=(self.img_rows, self.img_cols))
        '''

        self.dataset_name = 'CycleGAN'
        # DataLoader 오브젝트를 사용하여 전처리된 데이터셋을 Import 하다
        self.data_loader = DataLoader(dataset_name=self.dataset_name,
                                      img_res=(self.img_rows, self.img_cols))

        # Color Image Output을 뽑아내기 위한 Channel = 3
        self.OUTPUT_CHANNELS = 3

        # G,F 생성
        self.generator_vangogh = pix2pix.unet_generator(self.OUTPUT_CHANNELS, norm_type='instancenorm')
        self.generator_cezanne = pix2pix.unet_generator(self.OUTPUT_CHANNELS, norm_type='instancenorm')
        self.generator_monet = pix2pix.unet_generator(self.OUTPUT_CHANNELS, norm_type='instancenorm')

        # D_x, D_y 생성
        # self.discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)
        # self.discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)

        # self.generator_g.load_weights("C:/myproject/ai_project/content/models/vangogh.h5")
    '''
    # Image의 값을 0 ~ 255 -> -1 ~ 1로서 Normalization한다.
    def normalize(self, image):
        image = tf.cast(image, tf.float32)
        image = (image / 127.5) - 1
        return image
    '''
    def predict(self, img_file, style):
        img = self.data_loader.load_sample_data(img_file)  # 데이터 불러오기
        image = tf.cast(img, tf.float32)
        # img = img.resize(256, 256, 3)
        # image = (image / 127.5) - 1  # TensorShape([256, 256, 3])
        # image = tf.reshape(image, (1,) + image.shape)  # TensorShape([1, 256, 256, 3])

        if style == 0:
            vangogh_path = "C:/myproject/ai_project/content/models/vangogh.h5"
            self.generator_vangogh.load_weights(vangogh_path)
            transfer_img = self.generator_vangogh(image)  # vangogh
        elif style == 1:
            cezanne_path = 'C:/myproject/ai_project/content/models/cezanne.h5'
            self.generator_cezanne.load_weights(cezanne_path)
            transfer_img = self.generator_cezanne(image)  # cezann
        elif style == 2:
            monet_path = 'C:/myproject/ai_project/content/models/monet.h5'
            self.generator_monet.load_weights(monet_path)
            transfer_img = self.generator_monet(image)  # monet

        return transfer_img


    def generate_images(self, model, test_input):
        prediction_g = model(test_input)
        prediction = model(test_input, training=False)[0].numpy()
        prediction = (prediction * 127.5 + 127.5).astype(np.uint8)
        im = PIL.Image.fromarray(prediction)
        im.save("C:/myproject/ai_project/static/img/" + str(1) + ".jpg")

        '''
        plt.figure(figsize=(12, 12))

        display_list = [test_input[0], prediction[0]]
        title = ['Input Image', 'Predicted Image']

        plt.subplot()

        plt.subplot(1, 2, 1)
        plt.title(title[1])
        # getting the pixel values between [0, 1] to plot it.
        plt.imshow(display_list[1] * 0.5 + 0.5)
        plt.axis('off')

        plt.savefig('C:/myproject/ai_project/media/testing.png')
        '''
        return prediction_g

